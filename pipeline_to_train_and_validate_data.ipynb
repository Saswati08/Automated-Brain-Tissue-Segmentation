{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7PW_eUVec3g"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23500,
     "status": "ok",
     "timestamp": 1581323155589,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "uhDTeXROgNH0",
    "outputId": "88807381-86ac-4141-8c94-d183b2a008d1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1581193371009,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "gQioBZnytmI9",
    "outputId": "58071f26-987a-476c-d184-1ae8cf485a9d"
   },
   "outputs": [],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 958,
     "status": "ok",
     "timestamp": 1581210976267,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "IOiKmZ_Jux5N",
    "outputId": "3e0cd61a-889b-4760-9cf0-7ac91537236c"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1469,
     "status": "ok",
     "timestamp": 1581323169433,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "TJFSaZEPu4aF",
    "outputId": "e8beea2c-6bcf-48fe-f677-f33861c1ae01"
   },
   "outputs": [],
   "source": [
    "cd drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1581323170046,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "_g9UuaQru7oY",
    "outputId": "9f9a222d-3586-47c3-fd37-578b1b510e4d"
   },
   "outputs": [],
   "source": [
    "cd My Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1581323170701,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "Q-Wk1zheu_eB",
    "outputId": "c8c2e460-7f10-4585-f601-d889ad6d936d"
   },
   "outputs": [],
   "source": [
    "cd DL_assignment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-XNjpt-ZP51"
   },
   "outputs": [],
   "source": [
    "new_train_data = np.load('new_train_data_v4.npy')\n",
    "new_train_gt = np.load('new_train_gt_v4.npy')\n",
    "new_val_data = np.load('new_val_data_v4.npy')\n",
    "new_val_gt = np.load('new_val_gt_v4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IOyOGEY3CK3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "\n",
    "tensor_x = torch.Tensor(new_train_data) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(new_train_gt)\n",
    "\n",
    "my_dataset = data.TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "my_dataloader = data.DataLoader(my_dataset)\n",
    "\n",
    "\n",
    "tensor_vx = torch.Tensor(new_val_data)\n",
    "tensor_vy = torch.Tensor(new_val_gt)\n",
    "\n",
    "my_val = data.TensorDataset(tensor_vx,tensor_vy) # create your datset\n",
    "my_valoader = data.DataLoader(my_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hwuctYv-EU-f"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SegNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SegNet, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool1 = nn.Conv2d(64, 64, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.pool2 = nn.Conv2d(128, 128, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.pool3 = nn.Conv2d(256, 256, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.pool4 = nn.Conv2d(512, 512, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.pool5 = nn.Conv2d(512, 512, kernel_size = 2, stride = 2, padding = 0)\n",
    "        \n",
    "        self.unpool5 = nn.ConvTranspose2d(512, 512, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool4 = nn.ConvTranspose2d(512, 512, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool3 = nn.ConvTranspose2d(256, 256, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool2 = nn.ConvTranspose2d(128, 128, kernel_size = 2, stride = 2, padding = 0)\n",
    "        self.unpool1 = nn.ConvTranspose2d(64, 64,kernel_size = 2, stride = 2, padding = 0)\n",
    "\n",
    "        self.deconv5_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv5_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv5_3 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_1 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_2 = nn.ConvTranspose2d(512, 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv4_3 = nn.ConvTranspose2d(512, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_1 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_2 = nn.ConvTranspose2d(256, 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv3_3 = nn.ConvTranspose2d(256, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv2_1 = nn.ConvTranspose2d(128, 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv2_2 = nn.ConvTranspose2d(128, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv1_1 = nn.ConvTranspose2d(64, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.deconv1_2 = nn.ConvTranspose2d(64, 3, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(128)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(256)\n",
    "        self.batch_norm4 = nn.BatchNorm2d(512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        size_1 = x.size()\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_2(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x= self.pool1(x)\n",
    "        \n",
    "        size_2 = x.size()\n",
    "        x = self.conv2_1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        size_3 = x.size()\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        size_4 = x.size()\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool4(x)\n",
    "\n",
    "        size_5 = x.size()\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool5(x)\n",
    "\n",
    "        \n",
    "        x = self.unpool5(x)\n",
    "        x = self.deconv5_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv5_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv5_3(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool4(x)\n",
    "        x = self.deconv4_1(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv4_2(x)\n",
    "        x = self.batch_norm4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv4_3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool3(x)\n",
    "        x = self.deconv3_1(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv3_2(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv3_3(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool2(x)\n",
    "        x = self.deconv2_1(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2_2(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.unpool1(x)\n",
    "        x = self.deconv1_1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv1_2(x)\n",
    "        output = F.softmax(x, dim = 1)\n",
    "        return x, output\n",
    "\n",
    "def dice_loss(true, logits, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    # print(dice_loss, 1 - dice_loss)\n",
    "    return (dice_loss)\n",
    "\n",
    "def cal_confusion_matrix(output, label, val):\n",
    "  # if val == False:\n",
    "  output = output.cpu().detach()\n",
    "  output = np.array(output)\n",
    "  label = label.cpu().detach()\n",
    "  label = np.array(label)\n",
    "  confu_mat = np.zeros((3, 3))\n",
    "  pred_gt_equal = 0\n",
    "  tot_pix = 0\n",
    "  # print(output.shape)\n",
    "  # print(label.shape)\n",
    "  for i in range(output.shape[2]):\n",
    "    for j in range(output.shape[3]):\n",
    "      if val == True and label[0][i][j] == 0:\n",
    "        continue\n",
    "      tot_pix += 1\n",
    "      if output[0][0][i][j] > output[0][1][i][j] and output[0][0][i][j] > output[0][2][i][j]:\n",
    "        pred = 0\n",
    "      if output[0][1][i][j] > output[0][0][i][j] and output[0][1][i][j] > output[0][2][i][j]:\n",
    "        pred = 1\n",
    "      if output[0][2][i][j] > output[0][1][i][j] and output[0][2][i][j] > output[0][0][i][j]:\n",
    "        pred = 2\n",
    "      \n",
    "      #Confusion Matrix\n",
    "      # print(label[])\n",
    "      if val == False:\n",
    "        confu_mat[label[0][i][j]][pred] += 1 \n",
    "        if pred == label[0][i][j]:\n",
    "          pred_gt_equal += 1\n",
    "      else:\n",
    "        confu_mat[label[0][i][j] - 1][pred] += 1 \n",
    "        if pred == label[0][i][j] - 1:\n",
    "          pred_gt_equal += 1\n",
    "  return confu_mat\n",
    "\n",
    "\n",
    "def cal_dice_coefficient(output, label, val):\n",
    "  output = output.cpu().detach()\n",
    "  output = np.array(output)\n",
    "  label = label.cpu().detach()\n",
    "  label = np.array(label)\n",
    "  confu_mat = np.zeros((3, 3))\n",
    "  pred_gt_equal = 0\n",
    "  tot_pix = 0\n",
    "  # print(output.shape)\n",
    "  # print(label.shape)\n",
    "  for i in range(output.shape[2]):\n",
    "    for j in range(output.shape[3]):\n",
    "      if val == True and label[0][i][j] == 0:\n",
    "        continue\n",
    "      # print('here')\n",
    "      tot_pix += 1\n",
    "      if output[0][0][i][j] > output[0][1][i][j] and output[0][0][i][j] > output[0][2][i][j]:\n",
    "        pred = 0\n",
    "      if output[0][1][i][j] > output[0][0][i][j] and output[0][1][i][j] > output[0][2][i][j]:\n",
    "        pred = 1\n",
    "      if output[0][2][i][j] > output[0][1][i][j] and output[0][2][i][j] > output[0][0][i][j]:\n",
    "        pred = 2\n",
    "      if val == False:\n",
    "        if pred == label[0][i][j]:\n",
    "          pred_gt_equal += 1\n",
    "      else:\n",
    "        \n",
    "        if pred == label[0][i][j] - 1:\n",
    "          pred_gt_equal += 1\n",
    "  if tot_pix == 0:\n",
    "    return -1\n",
    "  dice_coefficient = pred_gt_equal/ (2 * tot_pix)\n",
    "  return dice_coefficient  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "20pfwjyGEf4P"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "model = SegNet()\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum = 0.9, weight_decay = 0.005)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 763,
     "status": "ok",
     "timestamp": 1581309472769,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "k_i5MsMb-Eul",
    "outputId": "5a28e861-ce5a-4be1-d824-bcfac9333a29"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "  print('true')\n",
    "else:\n",
    "  print('false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2258668,
     "status": "ok",
     "timestamp": 1581311974128,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "_28g4myfFxx3",
    "outputId": "a1bb2999-1e63-4852-98ea-b3f3b6cfd8f3"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "min_loss = 1\n",
    "for i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        mean_loss = 0\n",
    "        tot = 0\n",
    "        idx = 0\n",
    "        confusion_matrix = np.zeros((3, 3))\n",
    "        dice_coefficient = 0\n",
    "        for img, label in my_dataloader:\n",
    "            \n",
    "            img_r = torch.unsqueeze(img, 1)\n",
    "            # print(img_r.shape)\n",
    "            if torch.cuda.is_available():\n",
    "              img_r = img_r.cuda()\n",
    "            # label_r = torch.unsqueeze(label, 1)\n",
    "            label = label.type(torch.LongTensor)\n",
    "            if torch.cuda.is_available():\n",
    "              label = label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            # print(img_r.shape)\n",
    "            output, output_s = model(img_r)\n",
    "            # print(output.shape, label.shape)\n",
    "            loss = criterion(output, label)\n",
    "            # loss2 = dice_loss(label, output)\n",
    "            # print(loss2.item())\n",
    "            confusion_matrix += cal_confusion_matrix(output_s, label, False)\n",
    "            dice_coefficient += cal_dice_coefficient(output_s, label, False)\n",
    "            # tot += loss2.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            mean_loss += loss\n",
    "            idx += 1\n",
    "\n",
    "        print(idx)  \n",
    "        mean_loss /= idx\n",
    "        tot /= idx\n",
    "        dice_coefficient /= idx\n",
    "        end_time = time.time()\n",
    "        elapse_time = end_time - start_time\n",
    "        print(f'epoch {i} loss: {mean_loss}, elapse time: {elapse_time}',  dice_coefficient)\n",
    "        for i in range(confusion_matrix.shape[0]):\n",
    "          for j in range(confusion_matrix.shape[1]):\n",
    "            print(confusion_matrix[i][j], end = \" \")\n",
    "          print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        torch.save(model, 'segnet_model_deconv_conv' + str(epochs))\n",
    "            \n",
    "            # state_dict = model.module.state_dict()\n",
    "            # for key in state_dict.keys():\n",
    "            #     state_dict[key] = state_dict[key].cpu()\n",
    "            #     torch.save(state_dict, 'segnet_weight_baseline.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1581230811526,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "eLRV0iy1qrlv",
    "outputId": "0d6ad66a-ebd3-4b33-ad96-1e8a8d18936f"
   },
   "outputs": [],
   "source": [
    "output_s[0][2][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 44908,
     "status": "ok",
     "timestamp": 1581312056767,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "NhbdETLctB94",
    "outputId": "aa63ca27-b1d4-4f14-f44c-fa44af4fc831"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# model = torch.load('segnet_model_')\n",
    "# model.eval()\n",
    "mean_loss_v = 0\n",
    "tot_v = 0\n",
    "idx = 0\n",
    "tot_correct = 0\n",
    "tot_pixel = 0\n",
    "dice_coefficient = 0\n",
    "confusion_matrix_v = np.zeros((3, 3))\n",
    "with torch.no_grad():\n",
    "  for img_v, label_v in my_valoader:\n",
    "      \n",
    "      img_r = torch.unsqueeze(img_v, 1)\n",
    "      if torch.cuda.is_available():\n",
    "        img_r = img_r.cuda()\n",
    "      # img = img_v.type(torch.FloatTensor)\n",
    "      # label_r = torch.unsqueeze(label_v, 1)\n",
    "      label_v = label_v.type(torch.LongTensor)\n",
    "      if torch.cuda.is_available():\n",
    "        label_v = label_v.cuda()\n",
    "      output, output_s = model(img_r)\n",
    "      # print(output.shape, label.shape)\n",
    "      # loss = criterion(output_s, label_v)\n",
    "      # loss2 = dice_loss(label, output)\n",
    "      # print(loss2.item())\n",
    "      # print(type(output))\n",
    "      confusion_matrix_v += cal_confusion_matrix(output_s, label_v, True)\n",
    "      # print(cal_confusion_matrix(output_s, label_v, True))\n",
    "      if cal_dice_coefficient(output_s, label_v, True) != -1:\n",
    "        dice_coefficient += cal_dice_coefficient(output_s, label_v, True)\n",
    "      else:\n",
    "        idx -= 1\n",
    "      # print(mat)\n",
    "      \n",
    "      # print(confusion_matrix_v)\n",
    "      \n",
    "      # tot_v += loss2.item()\n",
    "      \n",
    "      \n",
    "      # mean_loss_v += loss\n",
    "      idx += 1\n",
    "\n",
    "# print(idx_v)  \n",
    "# mean_loss_v /= idx\n",
    "tot_v /= idx\n",
    "dice_coefficient /= idx\n",
    "end_time = time.time()\n",
    "# elapse_time = end_time - start_time\n",
    "# print(f'epoch {i} elapse time: {elapse_time}', dice_coefficient)\n",
    "print(dice_coefficient)\n",
    "print(confusion_matrix_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3809,
     "status": "ok",
     "timestamp": 1581323219678,
     "user": {
      "displayName": "Saswati Hazra",
      "photoUrl": "",
      "userId": "10649046827291398700"
     },
     "user_tz": -330
    },
    "id": "5NofUHG6YwJL",
    "outputId": "aacaef52-58e4-404b-dbb8-604bef556ebd"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = torch.load('segnet_model_deconv_conv10')\n",
    "model.eval()\n",
    "from torchsummary import summary\n",
    "summary(model, input_size = (1, 32, 32), batch_size = 1, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SF4rrecIjqra"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMna0R1/TAZToH5IRkENSUk",
   "collapsed_sections": [],
   "name": "2.3 of Q2.ipynb",
   "provenance": [
    {
     "file_id": "1CRB7uVg9QRZtE7XsDBcK6H5hhmeF684X",
     "timestamp": 1581243703546
    },
    {
     "file_id": "13zClI01v98jbNSDn7XxzW7yZ4cqNGaPS",
     "timestamp": 1581238693271
    },
    {
     "file_id": "1gd6KDJkPthsBjMCAeUgxkAwjtY3BLIXO",
     "timestamp": 1581190881062
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
